<!DOCTYPE html>
<html lang="en">
<!-- Head -->
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="description" content="Personal website of Saeed Ghoorchian.">
    <meta name="keywords" content="saeed, ghoorchian, bandits, online learning">
    <meta name="author" content="Saeed Ghoorchian">
    <meta name="google-site-verification" content="DqHQgF-Sk6MihTpwEmjWjg3Z4-siYNnklpLypAizZts" />

    <title>Saeed Ghoorchian</title>
    <link rel="icon" type="image/png" sizes="32x32" href="material/favicon-32x32.png">
    <!-- To use the Google icons -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <!-- To use the Font Awesome icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.2/css/academicons.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.2/css/academicons.min.css"/>
    
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Hind:300,400,500,600,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fjalla+One" >
    <link rel="stylesheet" type='text/css' href='https://fonts.googleapis.com/css?family=Open+Sans' >
    <!-- Style -->
    <link rel="stylesheet" href="material/MyStyle.css" >
    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    
</head>

<!-- Body -->
<body>
    
<section class="topnav section">
    <div class="container">
<!-- <div class="topnav"> -->
        <div class="row">
            
<!--             <div class="col-md-1"> -->
                <address>
<!--                 <div class="icons"> -->
                <ul class="icons">
        <!--          <li><a href="https://www.twitter.com/saeedghoorchian" alt="Twitter"><i class="fa fa-twitter" aria-hidden="true"></i></a></li> -->
            <li><a href="https://scholar.google.com/citations?user=Ro-q7woAAAAJ&hl=en" alt="Google Scholar" target="_blank"><i class="ai ai-google-scholar" aria-hidden="true"></i></a></li>
            <li><a href="https://www.linkedin.com/in/saeed-ghoorchian/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
            <li><a href="https://github.com/saeedghoorchian" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a></li>
                </ul>
                </address>
<!--              <a href="blog/blog_saeed.html" target="_blank">Blog</a> -->
<!--                 </div> -->
<!--            </div> -->
<!-- </div> -->
        </div>
    </div>
</section>
    
<!-- <section class="topnav-right section">
    <div class="container">
        <div class="row">
            <a href="blog/blog_saeed.html" target="_blank">Blog</a>
        </div>       
    </div>
</section> -->
<!--         <div class="topnav-right"> -->
<!--             <a href="#search">Search</a> -->
<!--             <a href="blog/blog_saeed.html" target="_blank">Blog</a> -->
<!--             <p style="font-size:16px;"><a href="blog/blog_saeed.html" target="_blank">Personal Blog</a> -->
<!--         </div> -->
   
<div id="main-wrapper">

<!-- profile -->
<header class="header">
    <div class="container">
        <div class="row">
          
            <div class="col-md-3">
                <div class="profile">
                    <img src="material/pic_saeed.jpeg" width="200" height="200" alt="Saeed Ghoorchian Image"/>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                </div>
            </div>
            <div class="col-md-9">
                <div class="name">
                    <h1><strong>Saeed Ghoorchian</strong></h1>
                </div>
                    <h4>About</h4>
                <p align="justify">
                    
                    My research focuses mainly on building machine learning methods to solve online decision-making problems under uncertainty.
                    To achieve this, I have worked on developing decision-making algorithms capable of learning the optimal action and feature observations in non-stationary environments with causal dependencies. 

                    Most existing machine learning methods, particularly in the era of big data, postulate the possibility of information acquisition with no limit and for free. This leads to deploying models that require observing all features' states before predicting a class label. In real-world problems, however, collecting beneficial information is often costly. For example, in online advertising problems, the advertiser can purchase information about target users to display personalized ads. As another example, in medical contexts, obtaining data for treatment recommendations mainly requires additional tests that are time- and money-consuming. How to maximize the model performance while keeping the cost of feature observations as low as possible? What if the reward distribution and features' cost distribution vary over time? Such cases frequently appear in real-world problems; for example, in personalized news recommendations, user preferences over news can change over time and exhibit various seasonality patterns. Hence, we need novel learning methods that, besides individual actions' rewards, learn the observations of the features' states and are robust to distribution shifts in the deployed environment.
                </p>

                <p align="justify">
                    Now, what if there are causal dependencies among actions' outcomes? A real-world example of this situation is the Covid-19 development within a country. During the Covid-19 pandemic, containing the virus outbreak has been one of the major concerns of governments. To this end, health authorities attempt to monitor the outbreak and detect the regions likely to become coronavirus hotspots. It is only natural that health authorities seek to find the regions that contribute the most to the total number of daily new cases in the country. Due to mobility between geographical areas, causal relations exist amongst total daily new cases (rewards) of regions (actions). How can the optimal candidate regions be detected for political interventions while dealing with statistical dependencies? 
                </p>

                <p align="justify">
                    My research during my PhD addresses the questions mentioned above and the like. 
                    
                    During my postdoc, I was doing research at the intersection of imitation learning, active learning, and inverse reinforcement learning, to design machine learning methods for explaining sequential decision-making based on demonstrated behavior by a sub-optimal learner.
                </p>

                <p align="justify"> 
                    Prior to my PhD, I completed my master studies in Mathematical Modelling in engineering within an Erasmus Mundus international joint master program at University of Hamburg and obtained a bachelor’s degree in Mathematics from Iran University of Science and Technology.
                </p>
        
                <h4>Research Interests</h4>
            <p>
            <ul>

                <li>Reinforcement Learning</li>
                <li>Imitation Learning</li>
                <li>Causality in Large Language Models</li>
                <li>Generative AI</li>
                <li>(Online) Recommender Systems</li>
            </ul>
            </p> 
            </div>
        </div>
    </div>
</header>

<!-- news -->
<section class="news section">
    <div class="container">
        <div class="row">
            <div class="col-md-3">
                <div class="section-title">
                    <h2>News</h2>
                </div>
            </div>
            <div class="col-md-9">
                <div class="row">
                    <div class="col-sm-12">
                        <ul>
                        <li><strong> April, 2025</strong> </li>
                        Our paper <a href="https://ieeexplore.ieee.org/document/10902019" target="_blank">'Non-Stationary Delayed Combinatorial Semi-Bandit With Causally Related Rewards'</a>, is out in the IEEE Open Journal of Signal Processing. 
                        <li><strong> March, 2025</strong> </li>
                        A preprint of our recent paper, "Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence", is available <a href="https://arxiv.org/pdf/2503.04219" target="_blank">'here'</a>.
                        <li><strong> June, 2024</strong> </li>
                          I’m starting a new position as Machine Learning Scientist at SAP.
                        <li><strong> April, 2024</strong> </li>
                          Our paper <a href="https://ieeexplore.ieee.org/document/10502231" target="_blank">'Contextual Multi-Armed Bandit with Costly Feature Observation in Non-stationary Environments'</a>, has been accepted for publication at the IEEE Open Journal of Signal Processing. 
                        <li><strong> March, 2024</strong> </li>
                          Our paper <a href="https://ieeexplore.ieee.org/document/10494875" target="_blank">'Non-stationary Linear Bandits with Dimensionality Reduction for Large-Scale Recommender Systems'</a>, has been accepted for publication at the IEEE Open Journal of Signal Processing. 
<!--                         <li><strong> February 16, 2024</strong> </li>
                          I started a research fellowship at the Ruhr-University Bochum.  -->
                        <li><strong> August, 2023</strong> </li>
                          I joined SAP as a visiting researcher.
                         <li><strong> April, 2023</strong> </li>
                          I successfully defended my PhD thesis titled "Online Learning under Partial Feedback" with magna cum laude. 🎉
                          <li><strong> September, 2022</strong> </li>
                            I will be Teaching Assistant for the course <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/decision-making/teaching/teaching-modules/" target="_blank">Introduction to Game Theory with Application in Multi-Agent Systems</a> 
                            during the winter semester at the University of Tübingen.
<!--                           <li><strong>July 28, 2022</strong> </li>
                            Presented our paper at the university of Tübingen. -->
                          <li><strong>July, 2022</strong> </li>
                            Presented our accepted paper at <a href="https://ijcai-22.org/" target="_blank">IJCAI 2022</a> in Vienna.
                          <li><strong>June, 2022</strong> </li>
                            Joined the <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/decision-making/team/" target="_blank">Decision Making group</a> 
                            at the University of Tübingen as a research assistant.
                          <li><strong>May, 2022</strong> </li>
                            Starting a freelance consultant position at <a href="https://www.datalyze-solutions.com/" target="_blank">Datalyze Solutions GmbH</a>, Germany.
<!--                             I will focus on developing algorithms for long-term task planning in changing environments. -->
                          <li><strong>April, 2022</strong> </li>
                            Our paper <a href="https://doi.org/10.24963/ijcai.2022/676" target="_blank">"Linear Combinatorial Semi-Bandit with Causally Related Rewards"</a>
                            has been accepted for publication at the 31st International Joint Conference on Artificial Intelligence (IJCAI). 
                          <li><strong>November, 2021</strong> </li>
                          Excited to serve students as Teaching Assistant at the University of Tübingen.
                          <li><strong>September, 2021</strong> </li>
                            Our paper <a href="https://doi.org/10.1109/TSC.2021.3113002" target="_blank">"Data-Driven Online Recommender Systems with Costly Information Acquisition"</a> 
                            has been accepted for publication at the IEEE Transactions on Services Computing (TSC).
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- publications -->
<section class="projects section">
    <div class="container">
        <div class="row">
            <div class="col-md-3">
                <div class="section-title">
                    <h2>Publications</h2>
                </div>
            </div>
            <div class="col-md-9">
                <div class="row">
                    <div class="col-sm-12">
<!--                         <p>* denotes equal contribution</p> -->

                        <div class="projects-item">
                            <p class="title"><a href="https://ieeexplore.ieee.org/abstract/document/9151218/" target="_blank"><strong>Multi-Armed Bandit for Energy-Efficient and Delay-Sensitive Edge Computing in Dynamic Networks with Uncertainty</strong></a> 
                            <p>Saeed Ghoorchian and Setareh Maghsudi</p>
                            <p><em>IEEE Transactions on Cognitive Communications and Networking (TCCN)</em>, 2020</p> 
                        </div>

                        <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.1109/TSC.2021.3113002" target="_blank"><strong>Data-Driven Online Recommender Systems with Costly Information Acquisition</strong></a> 
                            <p>Onur Atan, Saeed Ghoorchian, Setareh Maghsudi, and Mihaela van der Schaar</p>
                            <p><em>IEEE Transactions on Services Computing (TSC)</em>, 2021</p>
                        </div>
                        
                        <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.24963/ijcai.2022/676" target="_blank"><strong>Linear Combinatorial Semi-Bandit with Causally Related Rewards</strong></a> 
                            <p>Behzad Nourani-Koliji*, Saeed Ghoorchian*, and Setareh Maghsudi.</p>
                            <p><em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2022</p>
                        </div>
    
                        <div class="projects-item">

                            <p class="title"><a href="https://doi.org/10.48550/arXiv.2202.03167" target="_blank"><strong>Bayesian Non-stationary Linear Bandits for Large-Scale Recommender Systems</strong></a>
                            <p>Saeed Ghoorchian, Evgenii Kortukov, and Setareh Maghsudi</p>
                            <p><em>IEEE Open Journal of Signal Processing (OJSP)</em>, 2024</p>
                        </div>
                        
                        <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.48550/arXiv.2307.09388" target="_blank"><strong>Online Learning with Costly Features in Non-stationary Environments</strong></a>
                            <p>Saeed Ghoorchian, Evgenii Kortukov, and Setareh Maghsudi</p>
                            <p><em>IEEE Open Journal of Signal Processing (OJSP)</em>, 2024</p>
                        </div>
                        
                         <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.48550/arXiv.2307.09093" target="_blank"><strong>Non-Stationary Delayed Combinatorial Semi-Bandit With Causally Related Rewards</strong></a>
                            <p>Saeed Ghoorchian, Steven Bilaj, and Setareh Maghsudi</p>
                            <p><em>IEEE Open Journal of Signal Processing (OJSP)</em>, 2025</p>
                        </div>

                        <div class="projects-item">
                            <p class="title"><a href="https://arxiv.org/pdf/2503.04219" target="_blank"><strong>Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence</strong></a>
                            <p>Alireza Habibi*, Saeed Ghoorchian*, and Setareh Maghsudi</p>
                            <p><em>Under review</em>, 2025</p>
                        </div>

                        <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.48550/arXiv.2307.09093" target="_blank"><strong>Robust Inverse Reinforcement Learning under State Adversarial Perturbations</strong></a>
                            <p>Mine Melodi Caliskan, Saeed Ghoorchian, and Setareh Maghsudi</p>
                            <p><em>Under review</em>, 2025</p>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
    

<!-- publications -->
<!-- <section class="projects section">
    <div class="container">
        <div class="row">
            <div class="col-md-3">
                <div class="section-title">
                    <h2>Projects</h2>
                </div>
            </div>
            <div class="col-md-9">
                <div class="row">
                    <div class="col-sm-12">

                        <div class="projects-item">
                            <p class="title"><strong>Real-Time Task Planning in Changing Environments</strong></a> 
                        </div>

                        <div class="projects-item">
                            <p class="title"><a href="https://doi.org/10.1109/TSC.2021.3113002" target="_blank"><strong>Kernelized Principal Component Analysis and Support Vector Machines for Modelling Systems of High Complexity</strong></a> 
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section> -->


</div>

</body>

</html>
